---
output: pdf_document
---

## Dynamic Modeling

Above, we introduced fundemental concepts for dynamics. Memory, constraints, initial conditions, equilibrium, reciprocal influence -- these elements constitute the underlying dynamics and are ingredients to grapple with as researchers consider dynamic phenomenon. Dynamic mechanisms give rise to observed data, distributions, and statistical properties for us to witness and it is those observed data that we apply statistical models to. In a perfect world, researchers could put a magnifying glass up to their observed data and its statistical properties and clearly identify the underlying dynamics. Unfortunately we do not live in that world. Instead, there are a host of challenges that must be considered when researchers collect longitudinal data and estimate models to make inferences about dynamics. In this section we describe stationarity, dynamic panel bias, and ergodicity. Note that throughout the rest of the paper we replace the layman's term for $a$ (self-similarity) with its more common name in the statistical literature: autoregression, serial correlation, or autocorrelation -- all of these refer to the relationship between a state and itself over time.

### Stationarity

States and systems have statistical properties, stationarity is about the stability of those properties. Rachel's performance across time is called a time-series -- it is the trajectory of performance for a single unit (Rachel) over time. That trajectory has properties: it has a mean and a variance (and autocorrelation or serial correlation). If the mean is unstable then Rachel's performance either grows or decreases unconditionally over time. If instead the mean is stable, then Rachel's performance across time fluctuates but within the constraints of its memory and bounds on the system. Growth models assume no stationarity in the data they model, whereas virtually all other models used in the applied organizational literature assume that the data they are modeling are realizations of a stationary process. That is, they assume that the states and systems they are trying to estimate parameters for have properties at time $t$ that are the same as the properties at time $t + 1$. 

In simple terms, a stationary process has stable properties across time -- data that demonstrate trend, growth, or random walk behavior are (almost certainly) non-stationary. Here is the hard part: two independent time-series will appear related if both are non-stationary [@granger_spurious_1974; @kuljanin_cautionary_2011]. That is, if we measure Rachel's performance and it is consistent with a random walk and we also measure rainfall at Rachel's mother's house across the state and it demonstrates increasing trend for the day, even though these two things are completely unrelated we will more than likely find a relationship between them in a regression-based analysis like those presented at the start of this paper. There are many other articles that describe how to test for stationarity [e.g., @braun_spurious_2013; @jebb_time_2015], the point here is to convey how important this notion is. Our literature is not paying attention to random walks, we are not checking for memory, or serial correlation, or stationarity; we should be. 

That said, there is a class of models known as cointegration models that can be used to evaluate relationships in a non-stationary system. They are more complicated and require a deep understanding of mathematics and econometric modeling, but interested readers can see @engle_co-integration_1987, @johansen_estimation_1991, @phillips_optimal_1991, @phillips_statistical_1990, and @phillips_multiple_1986.

Again, stationarity describes statistical properties that result from the underlying dynamics. States may or may not have memory, they may or may not have lag relationships, or reciprocal influence, and may or may not be constrained by their initial conditions. These aspects are the underlying dynamics and the distributions that they give rise to have properties, stationarity is about those emergent statistical properties. Any system in equilibrium will be stationary, whereas unstable systems will be non-stationary.  

### Dynamic Panel Bias

Another challenge for dynamic modeling is dynamic panel bias, which is the combined effect of two issues. The first issue has to do with statistically accounting for memory. Remember that the dynamic equations above took the form:

\begin{equation}
y_{t} = a y_{t-1} + e_{t}
\end{equation}

\noindent where the only change is that we replaced performance with a generic $y$. The equation above has what is called a "lagged DV," where $y_{t}$ is predicted by the lagged DV: $y_{t-1}$. Including lagged DVs helps us *conceptually* represent dynamics [@keele_dynamic_2006], but including a lagged DV in a *model* applied to data with actual statistical properties causes the errors to correlate with the predictors and ultimately violate the well-known independence of errors assumption. This issue applies even when we are only considering a single unit (like Rachel) across time. 

The second issue arises when we are interested in relationships with a multiple-unit sample across time. Almost all organizational studies are multiple-unit -- they collect data on more than one participant. If the people in the sample are not perfectly exchangeable, which means that we can learn the same thing about performance and fatigue by studying either Bob or Rachel, we lose no information by restricting our analysis to one of them, then the parameter estimates are influenced by what is known as unobserved heterogeneity. Unobserved heterogeneity represents aggregate, stable individual differences. Rachel's fatigue over time may look different from Bob's fatigue over time due to unmeasured individual differences and states. These unacknowledged effects are responsible for individual differences on fatigue so they need to be incorporated in statistical models. We acknowledge them by incoporating unobserved heterogeneity, again it is a term that is meant to represent all of the unmeasured things that make Rachel's trajectory different from Bob's trajectory. 

In dynamic modeling, unobserved heterogeneity must be handled appropriately: if it is modeled as independent but in fact correlates with the model predictors then ommitted variables bias is introduced into the estimates, and if unobserved heterogeneity is ignored then serial correlation will be introduced into the errors. 

Dynamic panel bias is the combined effect of these two biases. Lagged DVs conceptually convey a dynamic process but they create estimation problems and researchers must account for unobserved heterogeneity. Unfortunately, the current workhorse in our literature to examine dynamic phenomena (the hierarchical linear, random-coefficient, or multi level model) is not well suited to handle dynamic panel bias.

### Ergodicity

In the section above we spoke about unobserved heterogeneity, which can be thought of as heterogeneity of individual differences or unit effects. That is, there are unmeasured differences that result in Rachel's trajectory being different from Bob's. An appropriate next question is, when is it reasonable to pool Rachel and Bob's data? When can we be confident in homogeneity of dynamics? This is the notion of ergodicity.

Ergodicity is another statistical characteristic of a process, and it is important because it determines whether or not researchers can generalize inferences of inter-individual variability from tests of between-unit differences to inferences of within-unit variability. To see the dilemma, consider the following. First, the standard statistical models in applied psychology and management, such as growth curves, multi-level models, mixture modeling, ANOVA, and factor analysis all focus on between-unit variation [@molenaar_manifesto_2004]. Second, researchers using these techniques run their computations on a sample drawn from a population and then generalize their results back to the population, so (a) the results live at the level of the population and (b) researchers assume that the population (or sub population in mixture modeling) is homogenous [@molenaar2009new]. These notions are fine on their own, but researchers tend to make an additional assumption that is unlikely to hold: because resuls live at the level of the population and because researchers assume that the population is homogenous they often also assume that the results apply to the individuals making up the population [@molenaar2008implications]. In other words, they assume that the results from a test of between-unit variation hold at the level of within-individual variation.

When processes are ergodic, this implicit assumption holds: the results of an analysis of between-unit differences generalize to within-unit patterns and vice versa [@molenaar2007psychological; @molenaar2008consequences]. Researchers can generalize with ergodic processes, they can use a multi-level model to assess between-unit patterns and then make statements about within-person relationships. But this generalization is rarely appropriate. A Gaussian process is non-ergodic if it is non-stationarity (e.g., it has time-varying trends) and/or heterogeneous across subjects (subject-specific dynamics). Stated simply, a Gaussian process is non-ergodic if it has trend and/or Susie's trajectory is different from Bob's. If either is violated, which is often the case, then standard analyses of between-subject differences (growth models, multi-level or random-coefficient models, mixture models, ANOVA, factor analysis) cannot be used to make within-person statements. In general, within-person inferences need to come from unpooled, subject-specific time-series data structures [@molenaar2009generalization]. The general notion to take from ergodicity (which merits greater discussion elsewhere) is that researchers need to pay attention to homogeneity of dynamics across units.

